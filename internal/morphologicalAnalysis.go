package internal

import (
	"bytes"
	"fmt"
	"log"
	"math"
	"os"
	"os/exec"
	"path/filepath"
	"strings"
)

// ãƒãƒ¼ãƒˆã‚’è¡¨ã™æ§‹é€ ä½“
type Note struct {
	ID       string
	NoteId   string
	Title    string
	Content  string
	Keywords []string
	TFIDF    map[string]float64
}

// MeCab ã‚’ä½¿ã£ã¦åè©ãƒ»å‹•è©ãƒ»å½¢å®¹è©ã‚’æŠ½å‡º
func ExtractKeywordsMeCab(text string) ([]string, error) {
	cmd := exec.Command("mecab")
	var out bytes.Buffer
	cmd.Stdout = &out
	cmd.Stdin = strings.NewReader(text)

	if err := cmd.Run(); err != nil {
		return nil, fmt.Errorf("MeCab ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: %v", err)
	}

	lines := strings.Split(out.String(), "\n")
	var keywords []string
	for _, line := range lines {
		parts := strings.Split(line, "\t")
		if len(parts) > 1 {
			features := strings.Split(parts[1], ",")
			if len(features) > 0 {
				wordType := features[0]
				if wordType == "åè©" || wordType == "å‹•è©" || wordType == "å½¢å®¹è©" {
					keywords = append(keywords, parts[0])
				}
			}
		}
	}
	return keywords, nil
}

// æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚€
func LoadNotesFromDir(noteDir string) ([]Note, error) {
	var notes []Note
	files, err := os.ReadDir(noteDir)
	if err != nil {
		return nil, err
	}

	for _, file := range files {
		if filepath.Ext(file.Name()) == ".md" {
			filePath := filepath.Join(noteDir, file.Name())
			content, err := os.ReadFile(filePath)
			if err != nil {
				log.Printf("âš ï¸ ãƒãƒ¼ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: %v\n", err)
				continue
			}

			// MeCab ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
			keywords, err := ExtractKeywordsMeCab(string(content))
			if err != nil {
				log.Printf("âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã‚¨ãƒ©ãƒ¼: %v\n", err)
				continue
			}

			notes = append(notes, Note{
				ID:       strings.TrimSuffix(file.Name(), ".md"),
				Content:  string(content),
				Keywords: keywords,
				TFIDF:    make(map[string]float64),
			})
		}
	}
	return notes, nil
}

// **TF-IDF ã‚’è¨ˆç®—**
func CalculateTFIDF(notes []Note) {
	// **TFï¼ˆå˜èªã®å‡ºç¾é »åº¦ï¼‰ã‚’è¨ˆç®—**
	tfMap := make(map[string]map[string]float64) // map[ãƒãƒ¼ãƒˆID]map[å˜èª]TFå€¤
	for _, note := range notes {
		tfMap[note.ID] = CalculateTF(note.Keywords)
	}

	// **IDFï¼ˆé€†æ–‡æ›¸é »åº¦ï¼‰ã‚’è¨ˆç®—**
	idfMap := CalculateIDF(notes)

	// **TF-IDF ã‚’è¨ˆç®—**
	for i := range notes {
		tfidf := make(map[string]float64)
		for word, tf := range tfMap[notes[i].ID] {
			idf := idfMap[word]
			tfidf[word] = tf * idf // TF-IDF = TF Ã— IDF
		}
		notes[i].TFIDF = tfidf
	}
}

// ğŸ· **TFï¼ˆå˜èªã®å‡ºç¾é »åº¦ï¼‰ã‚’è¨ˆç®—**
func CalculateTF(words []string) map[string]float64 {
	tf := make(map[string]float64)
	totalWords := len(words)

	for _, word := range words {
		tf[word]++
	}
	for word := range tf {
		tf[word] /= float64(totalWords)
	}
	return tf
}

// ğŸ“Š **IDFï¼ˆé€†æ–‡æ›¸é »åº¦ï¼‰ã‚’è¨ˆç®—**
func CalculateIDF(notes []Note) map[string]float64 {
	idf := make(map[string]float64)
	totalDocs := float64(len(notes))

	for _, note := range notes {
		seen := make(map[string]bool)
		for _, word := range note.Keywords {
			if !seen[word] {
				idf[word]++
				seen[word] = true
			}
		}
	}

	for word := range idf {
		idf[word] = math.Log(totalDocs / (1 + idf[word])) // IDF = log(ç·æ–‡æ›¸æ•° / (1 + å‡ºç¾æ–‡æ›¸æ•°))
	}
	return idf
}

// ğŸ›  **ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—**
func CosineSimilarity(vec1, vec2 map[string]float64) float64 {
	var dotProduct, normA, normB float64
	for key, valA := range vec1 {
		if valB, found := vec2[key]; found {
			dotProduct += valA * valB
		}
		normA += valA * valA
	}
	for _, valB := range vec2 {
		normB += valB * valB
	}
	if normA == 0 || normB == 0 {
		return 0
	}
	return dotProduct / (math.Sqrt(normA) * math.Sqrt(normB))
}

// `from` ã®ãƒãƒ¼ãƒˆã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
func GetNoteKeywords(note Note) map[string]float64 {
	tf := CalculateTF(note.Keywords) // TF ã‚’è¨ˆç®—
	return tf
}

// ğŸ” **é–¢é€£ãƒãƒ¼ãƒˆã‚’æ¤œç´¢**
func FindRelatedNotes(fromZettel Zettel, zettels []Zettel, threshold float64, tfidfMap map[string]map[string]float64) []string {
	var relatedIDs []string

	// âœ… `fromZettel` ã® TF-IDF ã‚’å–å¾—
	fromTFIDF, exists := tfidfMap[fromZettel.NoteID]
	if !exists {
		fmt.Println("âš ï¸ `TF-IDF` ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:", fromZettel.NoteID)
		return relatedIDs
	}

	// âœ… ä»–ã®ãƒãƒ¼ãƒˆã¨ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
	for _, zettel := range zettels {
		if zettel.NoteID == fromZettel.NoteID {
			continue // ğŸ”¥ **è‡ªåˆ†è‡ªèº«ã¯ã‚¹ã‚­ãƒƒãƒ—**
		}

		// `zettel` ã® TF-IDF ã‚’å–å¾—
		noteTFIDF, exists := tfidfMap[zettel.NoteID]
		if !exists {
			continue
		}

		// ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
		similarity := CosineSimilarity(fromTFIDF, noteTFIDF)
		if similarity >= threshold {
			relatedIDs = append(relatedIDs, zettel.NoteID)
		}
	}

	return relatedIDs
}

// âœ… å„ `Zettel` ã‹ã‚‰ `TF-IDF` ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
func ComputeTFIDFForZettels(zettels []Zettel) map[string]map[string]float64 {
	// ğŸ”¹ å…¨ãƒãƒ¼ãƒˆã®å˜èªãƒªã‚¹ãƒˆã‚’æ ¼ç´
	documents := make(map[string][]string)

	// âœ… ã™ã¹ã¦ã®ãƒãƒ¼ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†
	for _, zettel := range zettels {
		// ğŸ”¹ ãƒãƒ¼ãƒˆã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚€
		content, err := os.ReadFile(zettel.NotePath)
		if err != nil {
			fmt.Printf("âš ï¸ ãƒãƒ¼ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: %s (%v)\n", zettel.NotePath, err)
			continue
		}

		// ğŸ”¹ MeCab ãªã©ã‚’ä½¿ã£ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
		keywords, err := ExtractKeywordsMeCab(string(content))
		if err != nil {
			fmt.Printf("âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºå¤±æ•—: %s (%v)\n", zettel.NotePath, err)
			continue
		}

		// ğŸ”¹ `NoteID` ã‚’ã‚­ãƒ¼ã«å˜èªãƒªã‚¹ãƒˆã‚’ä¿å­˜
		documents[zettel.NoteID] = keywords
	}

	// âœ… `TF-IDF` ã‚’è¨ˆç®—
	return ComputeTFIDF(documents)
}

// âœ… `TF-IDF` ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
func ComputeTFIDF(documents map[string][]string) map[string]map[string]float64 {
	// ğŸ”¹ å„ãƒãƒ¼ãƒˆã® TFï¼ˆå˜èªã®å‡ºç¾é »åº¦ï¼‰
	tfMap := make(map[string]map[string]float64)

	// ğŸ”¹ IDFï¼ˆé€†æ–‡æ›¸é »åº¦ï¼‰ã®ãŸã‚ã®å˜èªå‡ºç¾ã‚«ã‚¦ãƒ³ãƒˆ
	idfCount := make(map[string]int)
	totalDocs := len(documents)

	// âœ… å„ãƒãƒ¼ãƒˆã® TF ã‚’è¨ˆç®—
	for docID, words := range documents {
		tf := make(map[string]float64)
		for _, word := range words {
			tf[word]++
		}

		// ğŸ”¹ TF ã‚’æ­£è¦åŒ–ï¼ˆå˜èªæ•°ã§å‰²ã‚‹ï¼‰
		for word := range tf {
			tf[word] /= float64(len(words))
		}
		tfMap[docID] = tf

		// ğŸ”¹ å„å˜èªãŒä½•å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å‡ºç¾ã—ãŸã‹ã‚«ã‚¦ãƒ³ãƒˆ
		seen := make(map[string]bool)
		for _, word := range words {
			if !seen[word] {
				idfCount[word]++
				seen[word] = true
			}
		}
	}

	// âœ… IDFï¼ˆé€†æ–‡æ›¸é »åº¦ï¼‰ã‚’è¨ˆç®—
	idfMap := make(map[string]float64)
	for word, count := range idfCount {
		idfMap[word] = math.Log(float64(totalDocs) / (1.0 + float64(count)))
	}

	// âœ… TF-IDF ã‚’è¨ˆç®—
	tfidfMap := make(map[string]map[string]float64)
	for docID, tf := range tfMap {
		tfidf := make(map[string]float64)
		for word, tfValue := range tf {
			tfidf[word] = tfValue * idfMap[word] // ğŸ”¥ TF Ã— IDF
		}
		tfidfMap[docID] = tfidf
	}

	return tfidfMap
}
